{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9f96b6-f713-43fe-a543-164a5372f1c5",
   "metadata": {},
   "source": [
    "# How does ALS work?\n",
    "\n",
    "In this track you will review basic concepts of matrix multiplication and matrix factorization, and dive into how the Alternating Least Squares algorithm works and what arguments and hyperparameters it uses to return the best recommendations possible. You will also learn important techniques for properly preparing your data for ALS in Spark.\n",
    "\n",
    "## Preparing the environment\n",
    "\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21458f8-1acd-43a2-9cc6-306b920957ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "from environment import SEED\n",
    "from sklearn.decomposition import NMF\n",
    "from pyspark.sql.types import (StructType, StructField,\n",
    "                               DoubleType, IntegerType, StringType, TimestampType)\n",
    "from pyspark.sql import SparkSession, Row, DataFrame as SparkDataframe, functions as F\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb12e47-14ed-4e04-bc56-4e38f659c2b3",
   "metadata": {},
   "source": [
    "### Connect to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067fae1d-87c8-420a-9970-2287108b60f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "                     .master('local[*]') \\\n",
    "                     .appName('spark_application') \\\n",
    "                     .config(\"spark.sql.repl.eagerEval.enabled\", True)  # eval DataFrame in notebooks\n",
    "                     .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "print(f'Spark version: {spark.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea8ed5-a73b-4a7f-9587-9dff5833f1d9",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "### Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bc1cfb4-8894-421a-a5c4-7eedcda4f1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (87585, 3)\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- imdbId: string (nullable = true)\n",
      " |-- tmdbId: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>movieId</th><th>imdbId</th><th>tmdbId</th></tr>\n",
       "<tr><td>1</td><td>0114709</td><td>862</td></tr>\n",
       "<tr><td>2</td><td>0113497</td><td>8844</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+-------+------+\n",
       "|movieId| imdbId|tmdbId|\n",
       "+-------+-------+------+\n",
       "|      1|0114709|   862|\n",
       "|      2|0113497|  8844|\n",
       "+-------+-------+------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the file\n",
    "schema_links = StructType([\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"imdbId\", StringType()),\n",
    "    StructField(\"tmdbId\", IntegerType())\n",
    "])\n",
    "links_data = spark.read.csv('data-sources/links.csv', header=True, schema=schema_links)\n",
    "\n",
    "# Reviewing the result\n",
    "links_data.createOrReplaceTempView(\"links\")\n",
    "print(f'Dataframe shape: ({links_data.count()}, {len(links_data.columns)})')\n",
    "links_data.printSchema()\n",
    "links_data.limit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c67a5b2-37f5-4cbb-bab5-f412f86b07b0",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d12db7-04bc-4be2-8175-b16903430dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (87585, 3)\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>movieId</th><th>title</th><th>genres</th></tr>\n",
       "<tr><td>1</td><td>Toy Story (1995)</td><td>Adventure|Animati...</td></tr>\n",
       "<tr><td>2</td><td>Jumanji (1995)</td><td>Adventure|Childre...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+----------------+--------------------+\n",
       "|movieId|           title|              genres|\n",
       "+-------+----------------+--------------------+\n",
       "|      1|Toy Story (1995)|Adventure|Animati...|\n",
       "|      2|  Jumanji (1995)|Adventure|Childre...|\n",
       "+-------+----------------+--------------------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the file\n",
    "schema_movies = StructType([\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"genres\", StringType())\n",
    "])\n",
    "movies_data = spark.read.csv('data-sources/movies.csv', header=True, schema=schema_movies)\n",
    "\n",
    "# Reviewing the result\n",
    "movies_data.createOrReplaceTempView(\"movies\")\n",
    "print(f'Dataframe shape: ({movies_data.count()}, {len(movies_data.columns)})')\n",
    "movies_data.printSchema()\n",
    "movies_data.limit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75095ada-7238-49c9-9dd3-e1a89eea4497",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33215eb1-d042-42f3-930a-494d386716cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 1995-01-09 05:46:44 - 2023-10-12 20:29:07\n",
      "Dataframe shape: (92234, 4)\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>userId</th><th>movieId</th><th>rating</th><th>timestamp</th></tr>\n",
       "<tr><td>28</td><td>7458</td><td>3.5</td><td>2023-09-22 12:42:52</td></tr>\n",
       "<tr><td>28</td><td>285593</td><td>3.0</td><td>2023-09-22 21:20:05</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+-------+------+-------------------+\n",
       "|userId|movieId|rating|          timestamp|\n",
       "+------+-------+------+-------------------+\n",
       "|    28|   7458|   3.5|2023-09-22 12:42:52|\n",
       "|    28| 285593|   3.0|2023-09-22 21:20:05|\n",
       "+------+-------+------+-------------------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the file\n",
    "schema_ratings = StructType([\n",
    "    StructField(\"userId\", IntegerType()),\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"rating\", DoubleType()),\n",
    "    StructField(\"timestamp\", IntegerType())\n",
    "])\n",
    "ratings_data = spark.read.csv('data-sources/ratings.csv', header=True, schema=schema_ratings)\n",
    "\n",
    "# Cleaning and mutating some columns\n",
    "ratings_data = ratings_data.withColumn('timestamp', F.to_timestamp(F.from_unixtime('timestamp')))\n",
    "date_range = ratings_data.select('timestamp').agg(F.min('timestamp'), F.max('timestamp')).collect()[0]\n",
    "print(f\"Date range: {date_range[0]} - {date_range[1]}\")\n",
    "\n",
    "# Taking just last month\n",
    "ratings_data = ratings_data.where('timestamp >= \"2023-09-12\"')\n",
    "\n",
    "# Reviewing the result\n",
    "ratings_data.createOrReplaceTempView(\"ratings\")\n",
    "print(f'Dataframe shape: ({ratings_data.count()}, {len(ratings_data.columns)})')\n",
    "ratings_data.printSchema()\n",
    "ratings_data.limit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e1e24-0945-4834-a483-8b542de864ae",
   "metadata": {},
   "source": [
    "### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa955bf1-1051-40df-b2c9-f809ee134fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (2000072, 4)\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>userId</th><th>movieId</th><th>tag</th><th>timestamp</th></tr>\n",
       "<tr><td>22</td><td>26479</td><td>Kevin Kline</td><td>2020-02-29 23:01:26</td></tr>\n",
       "<tr><td>22</td><td>79592</td><td>misogyny</td><td>2020-02-11 20:58:17</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+-------+-----------+-------------------+\n",
       "|userId|movieId|        tag|          timestamp|\n",
       "+------+-------+-----------+-------------------+\n",
       "|    22|  26479|Kevin Kline|2020-02-29 23:01:26|\n",
       "|    22|  79592|   misogyny|2020-02-11 20:58:17|\n",
       "+------+-------+-----------+-------------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the file\n",
    "schema_tags = StructType([\n",
    "    StructField(\"userId\", IntegerType()),\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"tag\", StringType()),\n",
    "    StructField(\"timestamp\", IntegerType())\n",
    "])\n",
    "tags_data = spark.read.csv('data-sources/tags.csv', header=True, schema=schema_tags)\n",
    "\n",
    "# Cleaning and mutating some columns\n",
    "tags_data = tags_data.withColumn('timestamp', F.to_timestamp(F.from_unixtime('timestamp')))\n",
    "\n",
    "# Reviewing the result\n",
    "tags_data.createOrReplaceTempView(\"tags\")\n",
    "print(f'Dataframe shape: ({tags_data.count()}, {len(tags_data.columns)})')\n",
    "tags_data.printSchema()\n",
    "tags_data.limit(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79709f1-ff5e-4b2b-8168-a273730bb43f",
   "metadata": {},
   "source": [
    "### Tables catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "544d8bd5-3e6f-4f7c-9f51-c4cee7a56df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='links', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='movies', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='ratings', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='tags', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312fbd4-a3bf-4e0a-b2c0-bd72010cc260",
   "metadata": {},
   "source": [
    "## User defined functions\n",
    "\n",
    "### getRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78bea52-5d03-4a36-8c13-c8c543b39126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMSE(pred, actual):\n",
    "\t\"\"\"Returns RMSE between predictions and actual observations\n",
    "\tParameters:\n",
    "\t\tpredictions: pandas dataframe of value predictions\n",
    "\t\tactual values: pandas dataframe of actual values that predictions are trying to predict\n",
    "\tReturns: RMSE value in decimal format\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tRMSE = (((pred - actual)**2).sum().sum()/(pred.shape[0]*pred.shape[1]))**.5\n",
    "\treturn round(RMSE, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1536d6e-63e6-482e-af8a-1776629328fd",
   "metadata": {},
   "source": [
    "### to_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1191b760-1187-40be-bae6-a7b6f801feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_long(df: SparkDataframe, \n",
    "            cols_a: List[str]=['User'], \n",
    "            col_b: str='Movie', \n",
    "            col_c: str='Rating') -> SparkDataframe:\n",
    "    \"\"\" \n",
    "    Converts traditional or \"wide\" dataframe into a \"row-based\" dataframe, \n",
    "    also known as a \"dense\" or \"long\" dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: array of columns with column names\n",
    "    - cols_a: list of columns name which serves as\n",
    "    - col_b: name of the second column that will hold the rest of columns name, excluding cols_a\n",
    "    - col_c: name of th third column that will hold the dataset values\n",
    "    \n",
    "    Returns: Row-based dataframe (cols_a, col_b, col_c) with no null values\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if c not in cols_a]\n",
    "    \n",
    "    # Create and explode an array of (column_name, column_value) structs\n",
    "    kvs = F.explode(F.array([\n",
    "        F.struct(F.lit(c).alias(col_b), F.col(c).alias(col_c)) \n",
    "        for c in cols\n",
    "    ])).alias(\"kvs\")\n",
    "    return (df.select(cols_a + [kvs])\n",
    "              .select(cols_a + [f\"kvs.{col_b}\", f\"kvs.{col_c}\"])\n",
    "              .filter(f\"{col_c} IS NOT NULL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cf604-25e8-42ff-992c-44a6099b0c27",
   "metadata": {},
   "source": [
    "# Knowdledge Base\n",
    "\n",
    "## Matrix multiplication: `np.dot` vs `np.matmul`\n",
    "\n",
    "To execute this operation, the number of columns in the first array need to be equal to the number of rows in the second array.\n",
    "\n",
    "### Ex. 1 - Matrix multiplication\n",
    "\n",
    "To understand matrix multiplication more directly, let's do some matrix operations manually.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Matrices `a` and `b` are Pandas dataframes. Review them.\n",
    "2. Work out the product of these two matrices on your own.\n",
    "3. Enter the values of the product of the a and b`a` and `b` matrices into the `product` array, created using `np.array()`.\n",
    "4. Use the validation on the last line of code to evaluate your estimate. The `.dot()` method multiplies two matrices together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf20fb0-e022-4520-a192-d411e138e01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz a:\n",
      "     0  1\n",
      "One  2  2\n",
      "Two  3  3\n",
      "\n",
      "Matriz b:\n",
      "     0  1\n",
      "One  1  2\n",
      "Two  4  4\n",
      "\n",
      "\n",
      "product:\n",
      "[[10 12]\n",
      " [15 18]]\n",
      "\n",
      "\n",
      "Manual operation equal?: True\n",
      "np.matmul equal to np.dpt?: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame([[2, 2], [3, 3]], index=['One', 'Two'])\n",
    "b = pd.DataFrame([[1, 2], [4, 4]], index=['One', 'Two'])\n",
    "\n",
    "print(f'''\n",
    "Matriz a:\n",
    "{a}\n",
    "\n",
    "Matriz b:\n",
    "{b}\n",
    "''')\n",
    "\n",
    "# Complete the matrix with the product of matrices a and b\n",
    "product = np.array([[2*1 + 2*4, 2*2 + 2*4], \n",
    "                    [3*1 + 3*4, 3*2 + 3*4]])\n",
    "print(f'''\n",
    "product:\n",
    "{product}\n",
    "''')\n",
    "\n",
    "# Run this validation to see how your estimate performs\n",
    "# For 2D arrays, np.dot is equal to np.matmul, np.matmul requires arrays not dataframes\n",
    "print(f'''\n",
    "Manual operation equal?: {np.array_equal(product, np.dot(a, b))}\n",
    "np.matmul equal to np.dpt?: {np.array_equal(np.matmul(a.values, b.values), np.dot(a, b))}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d51ea90-b656-4344-ad5e-46db7d1fa588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz a:\n",
      "1 2 3\n",
      "4 5 6\n",
      "\n",
      "Matriz b:\n",
      " 7  8\n",
      " 9 10\n",
      "11 12\n",
      "\n",
      "\n",
      "product:\n",
      "[[ 58  64]\n",
      " [139 154]]\n",
      "\n",
      "\n",
      "Manual operation equal?: True\n",
      "np.matmul equal to np.dpt?: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Another example\n",
    "a = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\n",
    "b = pd.DataFrame([[7, 8], [9, 10], [11, 12]])\n",
    "\n",
    "print(f'''\n",
    "Matriz a:\n",
    "{a.to_string(index=False, header=False)}\n",
    "\n",
    "Matriz b:\n",
    "{b.to_string(index=False, header=False)}\n",
    "''')\n",
    "\n",
    "# Complete the matrix with the product of matrices a and b\n",
    "product = np.array([[1*7 + 2*9 + 3*11, 1*8 + 2*10 + 3*12],\n",
    "                    [4*7 + 5*9 + 6*11, 4*8 + 5*10 + 6*12]])\n",
    "print(f'''\n",
    "product:\n",
    "{product}\n",
    "''')\n",
    "\n",
    "# Run this validation to see how your estimate performs\n",
    "# For 2D arrays, np.dot is equal to np.matmul, np.matmul requires arrays not dataframes\n",
    "print(f'''\n",
    "Manual operation equal?: {np.array_equal(product, np.dot(a, b))}\n",
    "np.matmul equal to np.dpt?: {np.array_equal(np.matmul(a.values, b.values), np.dot(a, b))}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb81c413-397d-4914-a5eb-d75b1fb5413e",
   "metadata": {},
   "source": [
    "### Ex. 2 - Non-negative matrix factorization\n",
    "\n",
    "It's possible for one matrix to have two equally close factorizations where one has all positive values and the other has some negative values.\n",
    "\n",
    "The matrix `M` has been factored twice using two different factorizations. Take a look at each pair of factor matrices `L` and `U`, and `W` and `H` to see the differences. Then use their products to see that they produce essentially the same product.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Use `print()` to view the `L` and `U` matrices. Notice that some values in matrices `L` and `U` are negative.\n",
    "2. Use `print()` to view the `W` and `H` matrices. Notice that all values in these two matrices are positive.\n",
    "3. The `L` and `U` matrices and `W` and `H` matrices have been multiplied together to produce the `LU` and `WH` matrices respectively. Use `getRMSE(product_matrix, original_matrix)` to see how close `LU` is to `M` compared to how close `WH` is to `M`. Are they similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d09125d8-bc9a-4719-82dc-1634fbff4893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How far is LU from M? RMSE: 0.072\n",
      "How far is WH from M? RMSE: 0.071\n"
     ]
    }
   ],
   "source": [
    "# Setting the matrix\n",
    "M = np.array([[1, 2, 1, 2],\n",
    "              [0, 0, 0, 0],\n",
    "              [1, 2, 2, 1],\n",
    "              [0, 0, 0, 0]])\n",
    "\n",
    "# Setting the factorized result of matrix M - possibility 1\n",
    "L = np.array([[1.00, 0.000000, 0.000000, 0],\n",
    "              [0.01, -0.421053, 0.098316, 1],\n",
    "              [1.00, 0.000000, 1.000000, 0],\n",
    "              [0.10, 1.000000, 0.000000, 0]])\n",
    "U = np.array([[1, 2.00, 1.000, 2.000000],\n",
    "              [0, -0.19, -0.099, -0.198000],\n",
    "              [0, 0.00, 1.000, -1.000000],\n",
    "              [0, 0.00, 0.000, 0.194947]])\n",
    "\n",
    "# Setting the factorized result of matrix M - possibility 2\n",
    "W = np.array([[2.61, 0.24, 0.00, 0.12],\n",
    "              [0.00, 0.05, 0.02, 0.17],\n",
    "              [1.97, 0.00, 0.58, 0.83],\n",
    "              [0.05, 0.00, 0.00, 0.00]])\n",
    "\n",
    "H = np.array([[0.38, 0.65, 0.34, 0.41],\n",
    "              [0.00, 1.20, 0.15, 3.72],\n",
    "              [0.42, 1.09, 1.38, 0.07],\n",
    "              [0.00, 0.11, 0.65, 0.17]])\n",
    "\n",
    "# Making the matrix multiplication of the possible factors\n",
    "LU = np.dot(L, U)\n",
    "WH = np.dot(W, H)\n",
    "\n",
    "# Calculate RMSE between LU and M\n",
    "print(\"How far is LU from M? RMSE:\", getRMSE(LU, M))\n",
    "\n",
    "# Calculate RMSE between WH and M\n",
    "print(\"How far is WH from M? RMSE:\", getRMSE(WH, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9541062f-67a4-42df-9e6a-47b5177d355f",
   "metadata": {},
   "source": [
    "### Matrix Factorization - Using `numpy.linalg.svd`\n",
    "```\n",
    "A == np.dot(US, V)\n",
    "```\n",
    "\n",
    "where:\n",
    "```\n",
    "U, S, V = np.linalg.svd(A)\n",
    "US = U * S\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4db7849b-ff20-4f18-91c4-7272e3064645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U * S:\n",
      " [[-3.082207   -0.70710678  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-3.082207    0.70710678  0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "V:\n",
      " [[-3.24442842e-01 -6.48885685e-01 -4.86664263e-01 -4.86664263e-01]\n",
      " [-4.66686951e-18 -4.75961049e-17  7.07106781e-01 -7.07106781e-01]\n",
      " [ 0.00000000e+00 -7.27606875e-01  4.85071250e-01  4.85071250e-01]\n",
      " [-9.45905303e-01  2.22565954e-01  1.66924465e-01  1.66924465e-01]]\n",
      "\n",
      "How far is USV from A? RMSE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2, 1, 2],\n",
    "              [0, 0, 0, 0],\n",
    "              [1, 2, 2, 1],\n",
    "              [0, 0, 0, 0]])\n",
    "\n",
    "U, S, V = np.linalg.svd(A, full_matrices=True)  # If True (default), u and vh have the shapes (..., M, M) \n",
    "                                                # and (..., N, N), respectively.\n",
    "                                                # Otherwise, the shapes are (..., M, K) and (..., K, N),\n",
    "                                                # respectively, where K = min(M, N).\n",
    "\n",
    "# Print the results\n",
    "print(\"U * S:\\n\", U * S)\n",
    "print(\"V:\\n\", V)\n",
    "\n",
    "# Calculate RMSE between WH and M\n",
    "USV = np.dot(U * S, V)\n",
    "print(\"\\nHow far is USV from A? RMSE:\", getRMSE(USV, A))\n",
    "np.allclose(A, USV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06985aa-38f4-449d-a81f-ef866c19abb3",
   "metadata": {},
   "source": [
    "### Matrix Factorization - Using `sklearn.decomposition.NMF`\n",
    "```\n",
    "A == np.dot(W, H)\n",
    "```\n",
    "\n",
    "where:\n",
    "```\n",
    "model = NMF(n_components=?, init='random', random_state=SEED)  # n_components: number of cols for the array W.\n",
    "                                                               # Components to infer\n",
    "W = fit_transform(A)\n",
    "H = model.components_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56bca683-2b01-42d5-ac3b-827745a6763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:\n",
      " [[1.40955799 0.18471342 1.13367593]\n",
      " [0.         0.         0.        ]\n",
      " [0.80188415 1.32305167 0.31916526]\n",
      " [0.         0.         0.        ]]\n",
      "H:\n",
      " [[0.32474734 1.27990823 0.55551258 0.84884422]\n",
      " [0.4617867  0.72266071 1.17496175 0.07324487]\n",
      " [0.40306531 0.05504503 0.         0.69683021]]\n",
      "\n",
      "How far is WH from A? RMSE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2, 1, 2],\n",
    "              [0, 0, 0, 0],\n",
    "              [1, 2, 2, 1],\n",
    "              [0, 0, 0, 0]])\n",
    "\n",
    "model = NMF(n_components=3, init='random', random_state=0)\n",
    "W = model.fit_transform(A) # W.shape = (4, 3)\n",
    "H = model.components_ # W.shape = (3, 4)\n",
    "\n",
    "# Print the results\n",
    "print(\"W:\\n\", W)\n",
    "print(\"H:\\n\", H)\n",
    "\n",
    "# Calculate RMSE between WH and M\n",
    "WH = np.dot(W, H)\n",
    "print(\"\\nHow far is WH from A? RMSE:\", getRMSE(WH, A))\n",
    "np.allclose(A, WH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2406af5-f3f2-4939-8ef9-c000ef4dd19f",
   "metadata": {},
   "source": [
    "## Data preparation for Spark ALS\n",
    "\n",
    "### Conventional Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5c0e8f0-a6cd-4275-8360-545718e19123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>userId</th><th>Batman Forever (1995)</th><th>Coco (2017)</th><th>Good Will Hunting (1997)</th><th>Incredibles, The (2004)</th><th>Shawshank Redemption, The (1994)</th></tr>\n",
       "<tr><td>16339</td><td>NULL</td><td>NULL</td><td>NULL</td><td>5.0</td><td>NULL</td></tr>\n",
       "<tr><td>58707</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>3.0</td></tr>\n",
       "<tr><td>65905</td><td>3.5</td><td>NULL</td><td>NULL</td><td>3.0</td><td>NULL</td></tr>\n",
       "<tr><td>78700</td><td>NULL</td><td>NULL</td><td>3.0</td><td>5.0</td><td>5.0</td></tr>\n",
       "<tr><td>72938</td><td>NULL</td><td>NULL</td><td>5.0</td><td>NULL</td><td>NULL</td></tr>\n",
       "<tr><td>86775</td><td>NULL</td><td>4.5</td><td>NULL</td><td>NULL</td><td>NULL</td></tr>\n",
       "<tr><td>177859</td><td>NULL</td><td>NULL</td><td>NULL</td><td>4.0</td><td>NULL</td></tr>\n",
       "<tr><td>78042</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>5.0</td></tr>\n",
       "<tr><td>95943</td><td>NULL</td><td>NULL</td><td>2.0</td><td>NULL</td><td>NULL</td></tr>\n",
       "<tr><td>143788</td><td>NULL</td><td>1.0</td><td>NULL</td><td>NULL</td><td>5.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+---------------------+-----------+------------------------+-----------------------+--------------------------------+\n",
       "|userId|Batman Forever (1995)|Coco (2017)|Good Will Hunting (1997)|Incredibles, The (2004)|Shawshank Redemption, The (1994)|\n",
       "+------+---------------------+-----------+------------------------+-----------------------+--------------------------------+\n",
       "| 16339|                 NULL|       NULL|                    NULL|                    5.0|                            NULL|\n",
       "| 58707|                 NULL|       NULL|                    NULL|                   NULL|                             3.0|\n",
       "| 65905|                  3.5|       NULL|                    NULL|                    3.0|                            NULL|\n",
       "| 78700|                 NULL|       NULL|                     3.0|                    5.0|                             5.0|\n",
       "| 72938|                 NULL|       NULL|                     5.0|                   NULL|                            NULL|\n",
       "| 86775|                 NULL|        4.5|                    NULL|                   NULL|                            NULL|\n",
       "|177859|                 NULL|       NULL|                    NULL|                    4.0|                            NULL|\n",
       "| 78042|                 NULL|       NULL|                    NULL|                   NULL|                             5.0|\n",
       "| 95943|                 NULL|       NULL|                     2.0|                   NULL|                            NULL|\n",
       "|143788|                 NULL|        1.0|                    NULL|                   NULL|                             5.0|\n",
       "+------+---------------------+-----------+------------------------+-----------------------+--------------------------------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conventional_df = (ratings_data.select('userId', 'movieId', 'rating')\n",
    "                               .join(movies_data.select('movieId', 'title')\n",
    "                                                .where(F.col('title').isin([\n",
    "                                                    'Good Will Hunting (1997)',\n",
    "                                                    'Batman Forever (1995)',\n",
    "                                                    'Incredibles, The (2004)',\n",
    "                                                    'Shawshank Redemption, The (1994)',\n",
    "                                                    'Coco (2017)'\n",
    "                                                ])), on=['movieId'])\n",
    "                               .groupBy('userId')\n",
    "                               .pivot('title')\n",
    "                               .agg(F.avg('rating'))\n",
    "                               .limit(10))\n",
    "conventional_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880baa36-b33f-4d0e-bad0-8f790f5b95ae",
   "metadata": {},
   "source": [
    "### RowBase Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "571ff54b-98a5-49fb-a9fa-4c7026a2fc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------+-------+\n",
      "|UserId|Movies                          |Ratings|\n",
      "+------+--------------------------------+-------+\n",
      "|16339 |Incredibles, The (2004)         |5.0    |\n",
      "|58707 |Shawshank Redemption, The (1994)|3.0    |\n",
      "|65905 |Batman Forever (1995)           |3.5    |\n",
      "|65905 |Incredibles, The (2004)         |3.0    |\n",
      "|72938 |Good Will Hunting (1997)        |5.0    |\n",
      "|78042 |Shawshank Redemption, The (1994)|5.0    |\n",
      "|78700 |Good Will Hunting (1997)        |3.0    |\n",
      "|78700 |Incredibles, The (2004)         |5.0    |\n",
      "|78700 |Shawshank Redemption, The (1994)|5.0    |\n",
      "|86775 |Coco (2017)                     |4.5    |\n",
      "+------+--------------------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using unpivot\n",
    "rowbase_df = (conventional_df.unpivot(['UserId'], conventional_df.columns[1:], 'Movies', 'Ratings')\n",
    "                             .where('Ratings IS NOT NULL')\n",
    "                             .sort('UserId', 'Movies'))\n",
    "rowbase_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b9e79e-97c6-49a9-be21-053790bd286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------+------+\n",
      "|userId|Movies                          |Rating|\n",
      "+------+--------------------------------+------+\n",
      "|16339 |Incredibles, The (2004)         |5.0   |\n",
      "|58707 |Shawshank Redemption, The (1994)|3.0   |\n",
      "|65905 |Batman Forever (1995)           |3.5   |\n",
      "|65905 |Incredibles, The (2004)         |3.0   |\n",
      "|72938 |Good Will Hunting (1997)        |5.0   |\n",
      "|78042 |Shawshank Redemption, The (1994)|5.0   |\n",
      "|78700 |Good Will Hunting (1997)        |3.0   |\n",
      "|78700 |Incredibles, The (2004)         |5.0   |\n",
      "|78700 |Shawshank Redemption, The (1994)|5.0   |\n",
      "|86775 |Coco (2017)                     |4.5   |\n",
      "+------+--------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a user defined function `to_long`\n",
    "row_base_df = to_long(conventional_df,\n",
    "                      cols_a=['userId'], col_b='Movies', col_c='Rating').sort('UserId', 'Movies')\n",
    "row_base_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8470c7-07a5-43be-ab76-8b4d9d24ca35",
   "metadata": {},
   "source": [
    "### Steps to get integer ID's in case userId and movieId were strings\n",
    "\n",
    "1. Extract unique userIds and movieIds\n",
    "2. Assign unique integers to each id\n",
    "3. Rejoin unique integer id's back to the ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af5ae43-c8b0-43e5-8e71-3e3a376a291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|userId|userIntId|\n",
      "+------+---------+\n",
      "| 16339|        0|\n",
      "| 58707|        1|\n",
      "| 65905|        2|\n",
      "+------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+-------+\n",
      "|              Movies|movieId|\n",
      "+--------------------+-------+\n",
      "|Incredibles, The ...|      0|\n",
      "|Shawshank Redempt...|      1|\n",
      "|Batman Forever (1...|      2|\n",
      "+--------------------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------+------+---------+-------+\n",
      "|              Movies|userId|Rating|userIntId|movieId|\n",
      "+--------------------+------+------+---------+-------+\n",
      "|Incredibles, The ...| 16339|   5.0|        0|      0|\n",
      "|Shawshank Redempt...| 58707|   3.0|        1|      1|\n",
      "|Batman Forever (1...| 65905|   3.5|        2|      2|\n",
      "|Incredibles, The ...| 65905|   3.0|        2|      0|\n",
      "|Good Will Hunting...| 78700|   3.0|        3|      3|\n",
      "|Incredibles, The ...| 78700|   5.0|        3|      0|\n",
      "|Shawshank Redempt...| 78700|   5.0|        3|      1|\n",
      "|Good Will Hunting...| 72938|   5.0|        4|      3|\n",
      "|         Coco (2017)| 86775|   4.5|        5|      4|\n",
      "|Incredibles, The ...|177859|   4.0|        6|      0|\n",
      "+--------------------+------+------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User integers IDs\n",
    "users = row_base_df.select('userId').distinct()\n",
    "users = users.coalesce(1)\n",
    "users = users.withColumn(\"userIntId\", F.monotonically_increasing_id()).persist()\n",
    "users.show(3)\n",
    "\n",
    "# Movie integer IDs\n",
    "movies = row_base_df.select(\"Movies\").distinct()\n",
    "movies = movies.coalesce(1)\n",
    "movies = movies.withColumn(\"movieId\", F.monotonically_increasing_id()).persist()\n",
    "movies.show(3)\n",
    "\n",
    "# Joining UserIds and MovieIds\n",
    "ratings_w_int_ids = (row_base_df.join(users, \"userId\", \"left\")\n",
    "                                .join(movies, \"Movies\", \"left\"))\n",
    "ratings_w_int_ids.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2732c7-0ffb-47d1-9a16-283358358607",
   "metadata": {},
   "source": [
    "### Ex. 3 Correct format and distinct users\n",
    "Take a look at the `df` dataframe. Notice that it is in conventional or \"wide\" format with a different movie in each column. Also notice that the User's and movie names are not in integer format. Follow the steps to properly prepare this data for ALS.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Import the `monotonically_increasing_id` package from `pyspark.sql.functions` and view the `R` dataframe using the `.show()` method.\n",
    "2. Use the `to_long()` function to convert the `df` dataframe into a `\"long\"` data frame. Call the new dataframe ratings.\n",
    "3. Create a dataframe called users that contains all the `.distinct()` users from the dataframe and repartition the dataframe into one partition using the `.coalesce(1)` method.\n",
    "4. Use the `monotonically_increasing_id()` method inside of `withColumn()` to create a new column in the `users` dataframe that contains a unique integer for each user. Call this column `userId`. Be sure to call the `.persist()` method on the final dataframe to ensure the new integer IDs persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3a83d4e-819e-4950-bb18-75d1c5910af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+----+----------+--------+\n",
      "|User            |Shreck|Coco|Swing Kids|Sneakers|\n",
      "+----------------+------+----+----------+--------+\n",
      "|James Alking    |3     |4   |4         |3       |\n",
      "|Elvira Marroquin|4     |5   |NULL      |2       |\n",
      "|Jack Bauer      |NULL  |2   |2         |5       |\n",
      "|Julia James     |5     |NULL|2         |2       |\n",
      "+----------------+------+----+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting the data\n",
    "df = spark.createDataFrame([\n",
    "        ['James Alking', 3, 4, 4, 3],\n",
    "        ['Elvira Marroquin', 4, 5, None, 2],\n",
    "        ['Jack Bauer', None, 2, 2, 5],\n",
    "        ['Julia James', 5, None, 2, 2]\n",
    "    ], schema=('User', 'Shreck', 'Coco', 'Swing Kids', 'Sneakers'))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "918a5794-2b95-4e35-8adf-257d1f8f79cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+------+\n",
      "|User            |Movie     |Rating|\n",
      "+----------------+----------+------+\n",
      "|Elvira Marroquin|Coco      |5     |\n",
      "|Elvira Marroquin|Shreck    |4     |\n",
      "|Elvira Marroquin|Sneakers  |2     |\n",
      "|Jack Bauer      |Coco      |2     |\n",
      "|Jack Bauer      |Sneakers  |5     |\n",
      "|Jack Bauer      |Swing Kids|2     |\n",
      "|James Alking    |Coco      |4     |\n",
      "|James Alking    |Shreck    |3     |\n",
      "|James Alking    |Sneakers  |3     |\n",
      "|James Alking    |Swing Kids|4     |\n",
      "|Julia James     |Shreck    |5     |\n",
      "|Julia James     |Sneakers  |2     |\n",
      "|Julia James     |Swing Kids|2     |\n",
      "+----------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataframe to the \"long\" format.\n",
    "ratings_df = (df.unpivot(['User'], df.columns[1:], 'Movie', 'Rating')\n",
    "                .where('Rating IS NOT NULL')\n",
    "                .sort('User', 'Movie'))\n",
    "ratings_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0c12dd2-05d8-44ef-8322-f35154e0817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|User            |userId|\n",
      "+----------------+------+\n",
      "|Elvira Marroquin|0     |\n",
      "|Jack Bauer      |1     |\n",
      "|James Alking    |2     |\n",
      "|Julia James     |3     |\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get unique users and repartition to 1 partition\n",
    "users = ratings_df.select(\"User\").distinct().coalesce(1)\n",
    "users = users.withColumn(\"userId\", F.monotonically_increasing_id()).persist()\n",
    "users.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78ec0b-581f-4fa4-b1a2-e3b4fd308607",
   "metadata": {},
   "source": [
    "### Ex. 4 Assigning integer id's to movies\n",
    "\n",
    "Let's do the same thing to the movies. Then let's join the new user IDs and movie IDs into one dataframe.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Use the `.select()` and the `.distinct()` methods to extract all unique Movies from the ratings dataframe.\n",
    "2. Repartition the movies dataframe to one partition using `coalesce()`.\n",
    "3. Complete the partial code provided to assign unique integer IDs to each movie. Name the new column `movieId` and call the `.persist()` method on the resulting dataframe.\n",
    "4. Join the ratings dataframe to the users dataframe and subsequently to the movies dataframe. Call the result movie_ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a5a220e-920f-40ae-90fe-541b40ef9d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|Movie     |movieId|\n",
      "+----------+-------+\n",
      "|Sneakers  |0      |\n",
      "|Coco      |1      |\n",
      "|Swing Kids|2      |\n",
      "|Shreck    |3      |\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get unique movie and repartition to 1 partition\n",
    "movies = ratings_df.select(\"Movie\").distinct().coalesce(1)\n",
    "movies = movies.withColumn(\"movieId\", F.monotonically_increasing_id()).persist()\n",
    "movies.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3dd976-a3a9-4b18-a699-556c520512fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------+------+-------+\n",
      "|Movie     |User            |Rating|userId|movieId|\n",
      "+----------+----------------+------+------+-------+\n",
      "|Shreck    |James Alking    |3     |2     |3      |\n",
      "|Coco      |James Alking    |4     |2     |1      |\n",
      "|Swing Kids|James Alking    |4     |2     |2      |\n",
      "|Sneakers  |James Alking    |3     |2     |0      |\n",
      "|Shreck    |Elvira Marroquin|4     |0     |3      |\n",
      "|Coco      |Elvira Marroquin|5     |0     |1      |\n",
      "|Sneakers  |Elvira Marroquin|2     |0     |0      |\n",
      "|Coco      |Jack Bauer      |2     |1     |1      |\n",
      "|Swing Kids|Jack Bauer      |2     |1     |2      |\n",
      "|Sneakers  |Jack Bauer      |5     |1     |0      |\n",
      "|Shreck    |Julia James     |5     |3     |3      |\n",
      "|Swing Kids|Julia James     |2     |3     |2      |\n",
      "|Sneakers  |Julia James     |2     |3     |0      |\n",
      "+----------+----------------+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join the ratings, users and movies dataframes\n",
    "movie_ratings_df = (ratings_df.join(users, \"User\", \"left\")\n",
    "                              .join(movies, \"Movie\", \"left\"))\n",
    "movie_ratings_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47eb76c-1ed4-4351-b53e-255535d2f4d3",
   "metadata": {},
   "source": [
    "## ALS parameters and hyperparameters\n",
    "\n",
    "### ALS model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b6380aa-ef8f-4dde-a36f-327b4ad6e37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|MovieId|Rating|\n",
      "+------+-------+------+\n",
      "| 13147|   2001|   2.0|\n",
      "|  3135| 163066|   4.0|\n",
      "|  6587|  66659|   3.5|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Review data\n",
    "df = ratings_data.select('userId', 'MovieId', 'Rating').repartition(5)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4bb2746-88cf-4ad7-84d9-5aeb7b65dafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 73917, Testing set: 18317\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=SEED)\n",
    "print(f\"Training set: {df_train.count()}, Testing set: {df_test.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c97b22ce-390e-42c1-abe9-be6b81c57c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ALS model\n",
    "als_model = ALS(userCol=\"userId\", itemCol=\"MovieId\", ratingCol=\"Rating\",\n",
    "                nonnegative=True, coldStartStrategy=\"drop\", implicitPrefs=False).fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b23239ff-42c3-456b-bb71-58a80721b1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|MovieId|Rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|  6654|  48304|   2.5| 2.7344885|\n",
      "|  6654|  57274|   2.5| 3.5387907|\n",
      "|  6654| 204318|   3.5| 3.0853581|\n",
      "+------+-------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on test dataset\n",
    "predictions = als_model.transform(df_test)\n",
    "predictions.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ce593-5caf-46f3-b6e4-0ece13eb3431",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54040e4b-9998-4304-92a1-56dc866f1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE: 0.9161828173411929\n",
      " MAE: 0.6896194025121015\n",
      "  R²: 0.1660545516063615\n",
      " MSE: 0.8393909547912431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete the evaluator code\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\")\n",
    "print(f'''\n",
    "RMSE: {evaluator.evaluate(predictions)}\n",
    " MAE: {evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})}\n",
    "  R²: {evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})}\n",
    " MSE: {evaluator.evaluate(predictions, {evaluator.metricName: \"mse\"})}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17596b-d7ed-447e-b4ba-9754ff5d3495",
   "metadata": {},
   "source": [
    "### Ex. 5 - Build out an ALS model\n",
    "\n",
    "Let's specify your first ALS model. Complete the code below to build your first ALS model.\n",
    "\n",
    "Recall that you can use the `.columns` method on the ratings data frame to see what the names of the columns are that contain user, movie, and ratings data. Spark needs to know the names of these columns in order to perform ALS correctly.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Before building our ALS model, we need to split the data into training data and test data. Use the `randomSplit()` method to split the ratings dataframe into training data and test data using an `0.8/0.2` split respectively and a seed for the random number generator of `SEED`.\n",
    "2. Tell Spark\n",
    "    - Which columns contain the `userCol`, `itemCol` and `ratingCol`. Use the `.columns` method if needed.\n",
    "3. Complete the hyperparameters.\n",
    "    - Set the `rank` to `10`,\n",
    "    - the `maxIter` to `15`,\n",
    "    - the `regParam` or lambda to `.1`,\n",
    "    - the `coldStartStrategy` to `\"drop\"`,\n",
    "    - the `nonnegative` argument should be set to `True`,\n",
    "    - and since our data contains explicit ratings, set the `implicitPrefs` argument to False.\n",
    "4. Now fit the als model to the training_data portion of the ratings data by calling the `.fit()` method on the training data provided. \n",
    "5. Generate predictions on the test data portion of the ratings data by calling the `.transform()` method on the test_data provided. Feel free to view the predictions by calling the `.show()` method on the predictions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2c5ee71-dc78-4e2d-bafd-0a0ad83848cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: long (nullable = true)\n",
      " |-- movieId: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     2|      3|   3.0|\n",
      "|     2|      1|   4.0|\n",
      "|     2|      2|   4.0|\n",
      "|     2|      0|   3.0|\n",
      "|     0|      3|   4.0|\n",
      "|     0|      1|   5.0|\n",
      "|     0|      0|   2.0|\n",
      "|     1|      1|   2.0|\n",
      "|     1|      2|   2.0|\n",
      "|     1|      0|   5.0|\n",
      "|     3|      3|   5.0|\n",
      "|     3|      2|   2.0|\n",
      "|     3|      0|   2.0|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "df = spark.createDataFrame([Row(userId=2, movieId=3, rating=3.0),\n",
    "                            Row(userId=2, movieId=1, rating=4.0),\n",
    "                            Row(userId=2, movieId=2, rating=4.0),\n",
    "                            Row(userId=2, movieId=0, rating=3.0),\n",
    "                            Row(userId=0, movieId=3, rating=4.0),\n",
    "                            Row(userId=0, movieId=1, rating=5.0),\n",
    "                            Row(userId=0, movieId=0, rating=2.0),\n",
    "                            Row(userId=1, movieId=1, rating=2.0),\n",
    "                            Row(userId=1, movieId=2, rating=2.0),\n",
    "                            Row(userId=1, movieId=0, rating=5.0),\n",
    "                            Row(userId=3, movieId=3, rating=5.0),\n",
    "                            Row(userId=3, movieId=2, rating=2.0),\n",
    "                            Row(userId=3, movieId=0, rating=2.0)])\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9be8cfc1-5d80-42ff-a943-e4a398bb97ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     2|      3|   3.0| 3.0715334|\n",
      "|     1|      2|   2.0| 3.5046484|\n",
      "|     3|      3|   5.0| 0.8877176|\n",
      "|     3|      2|   2.0| 1.7279035|\n",
      "+------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the df dataframe into training and test data\n",
    "(df_train, df_test) = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Set the ALS hyperparameters\n",
    "model = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "            rank=10, maxIter=15, regParam=0.1,\n",
    "            coldStartStrategy=\"drop\", nonnegative=True, implicitPrefs=False)\n",
    "\n",
    "# Fit the mdoel to the df_train\n",
    "model = model.fit(df_train)\n",
    "\n",
    "# Generate predictions on the df_test\n",
    "df_predictions = model.transform(df_test)\n",
    "df_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c22c6-29d0-4c53-9dd0-b4e114cbd88c",
   "metadata": {},
   "source": [
    "### Ex. 6 - Build RMSE evaluator\n",
    "\n",
    "Now that you know how to fit a model to training data and generate test predictions, you need a way to evaluate how well your model performs. For this we'll build an evaluator. Evaluators in Spark can be built out in various ways. For our purposes, we want a `regressionEvaluator` that calculates the `RMSE`. After we build our `regressionEvaluator`, we can fit the model to our data and generate predictions.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Import the required `RegressionEvaluator` package from the `pyspark.ml.evaluation` class. Already done!\n",
    "2. Complete the evaluator code, specifying the metric name to be `\"rmse\"`. Set the `labelCol` to the name of the column in our ratings data that contains our ratings (use the `.columns` method to see column names) and set the prediction column name to `\"prediction\"`.\n",
    "3. Confirm that the evaluator was properly created by extracting each of the three parameters from it. Do this by running the following 3 lines of code, each within a print statement:\n",
    "```\n",
    "evaluator.getMetricName()\n",
    "evaluator.getLabelCol()\n",
    "evaluator.getPredictionCol()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3aac89e-d50b-4999-ac8e-36f5b4d92f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse\n",
      "rating\n",
      "prediction\n"
     ]
    }
   ],
   "source": [
    "# Complete the evaluator code\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Extract the 3 parameters\n",
    "print(evaluator.getMetricName())\n",
    "print(evaluator.getLabelCol())\n",
    "print(evaluator.getPredictionCol())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56658c0-9750-461b-ac33-85d7d26b9f98",
   "metadata": {},
   "source": [
    "### Ex. 7 - Get RMSE\n",
    "\n",
    "Now that you know how to build a model and generate predictions, and have an evaluator to tell us how well it predicts ratings, we can calculate the `RMSE` to see how well an ALS model performed. We'll use the evaluator that we built in the previous exercise to calculate and print the rmse.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Call the `.evaluate()` method on our evaluator to calculate our `RMSE` on the test predictions dataframe. Call the result `RMSE`.\n",
    "2. Print the `RMSE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff4d7841-9be1-4ec3-b7e5-62ed42249689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1939682652076633\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the \"df_predictions\" dataframe\n",
    "RMSE = evaluator.evaluate(df_predictions)\n",
    "\n",
    "# Print the RMSE\n",
    "print (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1bfcef-d3b7-45e6-bee3-784106b2fa99",
   "metadata": {},
   "source": [
    "## Close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ebc4ec7-959d-469e-ae7c-7e706ea129ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
